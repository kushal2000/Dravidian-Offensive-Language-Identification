{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tamil_ulmfit.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wI0Wmn0xHa5w","executionInfo":{"status":"ok","timestamp":1610649032133,"user_tz":-330,"elapsed":228244,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"fd1d35ff-ce07-489f-baa5-11420d26783d"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount = True)\n","import os\n","root_path = 'gdrive/My Drive/EACL/'\n","os.chdir(root_path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JqTkTrJhKKji","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610649049711,"user_tz":-330,"elapsed":12530,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"2468aae9-b63a-47c9-ceea-3cf32ed734c1"},"source":["!pip install sentencepiece\n","!pip install transformers\n","!pip install demoji"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n","\r\u001b[K     |▎                               | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 23.6MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 29.0MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 27.9MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 29.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 32.2MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 23.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 21.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 23.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 21.5MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 21.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 21.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 21.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 21.5MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 21.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 21.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 21.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 21.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 21.5MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/40/866cbfac4601e0f74c7303d533a9c5d4a53858bd402e08e3e294dd271f25/transformers-4.2.1-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 16.3MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 39.1MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 51.7MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.3.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c88ea33a6ef91463cfea6b1f7ec60b0ad5b305c32fe6d785e1de49dda995099d\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.1\n","Collecting demoji\n","  Downloading https://files.pythonhosted.org/packages/88/6a/34379abe01c9c36fe9fddc4181dd935332e7d0159ec3fae76f712e49bcea/demoji-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from demoji) (2.23.0)\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n","Installing collected packages: colorama, demoji\n","Successfully installed colorama-0.4.4 demoji-0.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2Emp2LJ4gL2","executionInfo":{"status":"ok","timestamp":1610649233984,"user_tz":-330,"elapsed":195352,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"18f56b75-ebad-4cee-bcb8-4f6a9adfdf33"},"source":["!pip install git+git://github.com/irshadbhat/indic-trans.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting git+git://github.com/irshadbhat/indic-trans.git\n","  Cloning git://github.com/irshadbhat/indic-trans.git to /tmp/pip-req-build-9eyfqoqd\n","  Running command git clone -q git://github.com/irshadbhat/indic-trans.git /tmp/pip-req-build-9eyfqoqd\n","Collecting pbr\n","  Using cached https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from indictrans==1.2.3) (1.15.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from indictrans==1.2.3) (0.16.0)\n","Requirement already satisfied: cython>=0.24.0a0 in /usr/local/lib/python3.6/dist-packages (from indictrans==1.2.3) (0.29.21)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from indictrans==1.2.3) (1.19.5)\n","Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from indictrans==1.2.3) (1.4.1)\n","Building wheels for collected packages: indictrans\n","  Building wheel for indictrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for indictrans: filename=indictrans-1.2.3-cp36-cp36m-linux_x86_64.whl size=337563794 sha256=cdb67cf0494028ae8d969452329b8a4c1e7d6ca92aa1c398f8af23729dd41c12\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-uovib90c/wheels/01/a9/02/ca41463296c4ea023505525a9e355c68f3a71225c81495e6d7\n","Successfully built indictrans\n","Installing collected packages: pbr, indictrans\n","Successfully installed indictrans-1.2.3 pbr-5.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q9u99p-tJxBT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610649252476,"user_tz":-330,"elapsed":8657,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"a56ba4bf-4871-40dd-ebbb-952253737538"},"source":["from fastai.text import *\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import pickle\n","import sentencepiece as spm\n","import re\n","import pdb\n","import pandas as pd\n","from transformers import BertTokenizer, BertForSequenceClassification\n","import torch\n","import copy\n","from transformers import BertModel, RobertaModel, BertTokenizer, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, random_split, DataLoader, IterableDataset, ConcatDataset\n","import sklearn\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import f1_score \n","from tqdm import tqdm\n","import demoji \n","from indictrans import Transliterator\n","demoji.download_codes() \n","plt.rcParams['figure.figsize'] = [15, 8]\n","plt.rcParams.update({'font.size': 8})\n","RANDOM_SEED = 42\n","path = Path('./')\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading emoji data ...\n","... OK (Got response in 0.13 seconds)\n","Writing emoji data to /root/.demoji/codes.json ...\n","... OK\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tho9pExUKIgp","executionInfo":{"status":"ok","timestamp":1610649252477,"user_tz":-330,"elapsed":8434,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"c0ef4fcb-aaa9-4e6a-c538-e30c127d8024"},"source":["import fastai, torch\n","fastai.__version__ , torch.__version__"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('1.0.61', '1.7.0+cu101')"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"NGTSVOBUKST9","executionInfo":{"status":"ok","timestamp":1610649252478,"user_tz":-330,"elapsed":7277,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["def random_seed(seed_value, use_cuda):\n","    np.random.seed(seed_value)  \n","    torch.manual_seed(seed_value)  \n","    random.seed(seed_value)\n","    np.random.seed(seed_value)  \n","    torch.manual_seed(seed_value)  \n","    random.seed(seed_value)\n","    if use_cuda:\n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value)  \n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","random_seed(RANDOM_SEED, True)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"XG02yIg7cdtK","executionInfo":{"status":"ok","timestamp":1610649252479,"user_tz":-330,"elapsed":6444,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["def handle_all_caps(t: str) -> str:\n","    tokens = t.split()\n","    tokens = replace_all_caps(tokens)\n","    return ' '.join(tokens)\n","\n","def handle_upper_case_first_letter(t: str) -> str:\n","    tokens = t.split()\n","    tokens = deal_caps(tokens)\n","    return ' '.join(tokens)\n","\n","def lower_case_everything(t: str) -> str:\n","    return t.lower().replace('@user', '').replace('#tag ', '').replace('rt ', '').strip()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7FFx43hfd82","executionInfo":{"status":"ok","timestamp":1610649253249,"user_tz":-330,"elapsed":6146,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["class CodeMixedTamilTokenizer(BaseTokenizer):\n","    def __init__(self, lang:str):\n","        self.lang = lang\n","        self.sp = spm.SentencePieceProcessor()\n","        self.sp.Load(str(path/\"./Tamil/taen_spm.model\"))\n","        \n","    def tokenizer(self, t:str) -> List[str]:\n","        return self.sp.EncodeAsPieces(t)\n","\n","sp = spm.SentencePieceProcessor()\n","sp.Load(str(path/\"./Tamil/taen_spm.model\"))\n","itos = [sp.IdToPiece(int(i)) for i in range(8000)]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-_IjvvRF6S7k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610649253251,"user_tz":-330,"elapsed":5504,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"30777f27-7919-4016-cf72-45d5b19b2a4d"},"source":["itos[:20]"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['xxunk',\n"," 'xxbos',\n"," 'xxeos',\n"," 'xxpad',\n"," 'xxfld',\n"," 'xxmaj',\n"," 'xxup',\n"," 'xxrep',\n"," 'xxwrep',\n"," '.',\n"," ',',\n"," '▁',\n"," 's',\n"," 'a',\n"," '=\"',\n"," 'in',\n"," 'doc',\n"," 't',\n"," 'il',\n"," 'i']"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"c0GU0UcvKaVF","executionInfo":{"status":"ok","timestamp":1610649253252,"user_tz":-330,"elapsed":4521,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["class Dataset():\n","    def __init__(self, train_data, val_data, test_data):\n","        self.train_data = train_data\n","        self.val_data = val_data\n","        self.test_data = test_data\n","        # self.batch_size = batch_size\n","\n","        self.label_dict = {}\n","        \n","        self.count_dic = {}\n","\n","        self.trn = Transliterator(source='tam', target='eng', build_lookup=True)\n","\n","        self.train_df = pd.DataFrame(self.process_data(self.train_data))\n","        self.val_df = pd.DataFrame(self.process_data(self.val_data))\n","        self.test_df = pd.DataFrame(self.process_data(self.test_data, test = True))\n","\n","    def is_english(self, s: str) -> bool:\n","        if len(re.findall(u'[\\u0900-\\u097F]', s)) <= 1000:\n","            return True\n","        return False\n","\n","    def process_data(self, data, test = False):\n","        sentences, labels = [], []\n","        print(len(data))\n","        for line in data:\n","            sentence = line.strip().split('\\t')\n","            if not test:\n","                label = sentence.pop()\n","                if label not in self.label_dict:\n","                    self.label_dict[label] = len(self.label_dict)\n","                labels.append(self.label_dict[label])\n","                self.count_dic[label] = self.count_dic.get(label, 0) + 1\n","            sentence = ' '.join(sentence)\n","            emoji_dict = demoji.findall(sentence)\n","\n","            # if not self.is_english(sentence):\n","            #     print(sentence)\n","            #     sentence = self.trn.transform(sentence)\n","            #     print(sentence)\n","\n","            sentence = self.trn.transform(sentence)\n","\n","            if len(emoji_dict): \n","                for emoji, text in emoji_dict.items():\n","                    sentence = sentence.replace(emoji, ' '+text+' ')\n","                    sentence = ' '.join(sentence.split())\n","            \n","            sentences.append(sentence)\n","            \n","            # labels.append(label)\n","            \n","        if test: return {'input': sentences}\n","        return {'input': sentences, 'label': (labels)}"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nVNrDikRVCsT","executionInfo":{"status":"ok","timestamp":1610649320731,"user_tz":-330,"elapsed":71095,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"2c446366-2f33-497c-8917-a2d4ac88eecc"},"source":["with open('Dataset/tamil_offensive_full_train.csv', 'r') as f:\n","    train_data = f.readlines()\n","with open('Dataset/tamil_offensive_full_dev.csv', 'r') as f:\n","    val_data = f.readlines()\n","with open('Dataset/tamil_offensive_full_test.csv', 'r') as f:\n","    test_data = f.readlines()\n","data = Dataset(train_data, val_data, test_data)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["35139\n","4388\n","4392\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n1bzEqA9x8e1","executionInfo":{"status":"ok","timestamp":1610649320747,"user_tz":-330,"elapsed":69599,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"a2b5128c-d4ba-4ddd-c1b2-5b616a70a279"},"source":["data.label_dict"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Not_offensive': 0,\n"," 'Offensive_Targeted_Insult_Group': 3,\n"," 'Offensive_Targeted_Insult_Individual': 5,\n"," 'Offensive_Targeted_Insult_Other': 2,\n"," 'Offensive_Untargetede': 4,\n"," 'not-Tamil': 1}"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"Y5rwwJaX9a6V","executionInfo":{"status":"ok","timestamp":1610649320748,"user_tz":-330,"elapsed":69110,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"6769f264-5719-4e24-b20c-8948e4c011e9"},"source":["data.test_df.head()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>14.12.2018 epo trailer pathutu irken ... Semay...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Paka thana poro movie la Enna irukunu</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>“U kena tunggu lebih lama lagi untuk tahu saya...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Suriya anna vera level anna mass</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>suma kaththaatha da sound over a pooda kudaath...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               input\n","0  14.12.2018 epo trailer pathutu irken ... Semay...\n","1              Paka thana poro movie la Enna irukunu\n","2  “U kena tunggu lebih lama lagi untuk tahu saya...\n","3                   Suriya anna vera level anna mass\n","4  suma kaththaatha da sound over a pooda kudaath..."]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-UUWTmi19nFa","executionInfo":{"status":"ok","timestamp":1610649320749,"user_tz":-330,"elapsed":68497,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"fb0792d7-f43f-4b63-c263-c9498ba6ca1d"},"source":["from collections import Counter\n","Counter(data.train_df['label'])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({0: 25425, 1: 1454, 2: 454, 3: 2557, 4: 2906, 5: 2343})"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"u4-BDQDW9JDB","executionInfo":{"status":"ok","timestamp":1610649320750,"user_tz":-330,"elapsed":67919,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["label_cols = ['label']\n","text_cols = ['input']"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jek1nth594pZ","executionInfo":{"status":"ok","timestamp":1610649320751,"user_tz":-330,"elapsed":67250,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["taen_vocab = Vocab(itos)\n","tokenizer = Tokenizer(lang='taen', tok_func=CodeMixedTamilTokenizer)\n","tokenizer.pre_rules.append(lower_case_everything)\n","tokenizer.pre_rules.append(handle_all_caps)\n","tokenizer.pre_rules.append(handle_upper_case_first_letter)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EhRZu892_AS-","executionInfo":{"status":"ok","timestamp":1610649320752,"user_tz":-330,"elapsed":66545,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"83eba016-2262-4ad7-dad3-310df85623cb"},"source":["tokenizer.special_cases, tokenizer.pre_rules, tokenizer.post_rules"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['xxunk',\n","  'xxpad',\n","  'xxbos',\n","  'xxeos',\n","  'xxfld',\n","  'xxmaj',\n","  'xxup',\n","  'xxrep',\n","  'xxwrep'],\n"," [<function fastai.text.transform.fix_html>,\n","  <function fastai.text.transform.replace_rep>,\n","  <function fastai.text.transform.replace_wrep>,\n","  <function fastai.text.transform.spec_add_spaces>,\n","  <function fastai.text.transform.rm_useless_spaces>,\n","  <function __main__.lower_case_everything>,\n","  <function __main__.handle_all_caps>,\n","  <function __main__.handle_upper_case_first_letter>],\n"," [<function fastai.text.transform.replace_all_caps>,\n","  <function fastai.text.transform.deal_caps>])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"QG8D74DW_B6z","executionInfo":{"status":"ok","timestamp":1610649320753,"user_tz":-330,"elapsed":65271,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"7093fe3e-be7e-4da3-8495-7e4493775e58"},"source":["tokens = tokenizer.process_all(['Tell me about TOUR self, mujhe jaanna hai'])\n","''.join(tokens[0])"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'▁tell▁me▁about▁tour▁self,▁mujhe▁jaanna▁hai'"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"id":"q-4dM6Jn_EU6","executionInfo":{"status":"ok","timestamp":1610649324430,"user_tz":-330,"elapsed":68476,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"35ef8b82-f667-4b22-b92d-25f83e613a8b"},"source":["data_lm = TextLMDataBunch.from_df(path=path, train_df=data.train_df, valid_df=data.val_df, test_df=data.test_df, tokenizer=tokenizer, vocab=taen_vocab, label_cols=label_cols, text_cols=text_cols)"],"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return np.array(a, dtype=dtype, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":294},"id":"oQRmz0G-_std","executionInfo":{"status":"ok","timestamp":1610649335488,"user_tz":-330,"elapsed":78671,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"49594c3f-e181-489f-c754-73f4f041a28f"},"source":["data_lm.show_batch()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/fastai/text/data.py:339: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n","  idx_min = (t != self.pad_idx).nonzero().min()\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>idx</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . . ▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on ▁x x bo s ▁ip po ▁in tha ▁tra il er ▁ ah ▁park ura vana ▁oru ▁ like ▁po</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>. . . ▁x x bo s ▁varum ▁thi rai ▁ yang um ▁e tu thi kkum ▁pa ya varu kirar ▁s 3 ▁x x bo s ▁la u gh ▁ri ot ▁f rom ▁0 . 24 ▁dai ▁kel ava ▁x x bo s ▁un galuku ▁ver a ▁vel aya ▁il aya . . sam e ▁s tor y ▁ , ▁sam e ▁sc ri p t . ▁ad vi</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>▁por om ? ? ▁tha lai var : s we et ▁sa ap ida ▁por om . . . ▁ver a ▁le vel . . . ▁x x bo s ▁at li ▁math i ri ▁mutt al u kal ▁kan du ▁padi kkat tum ▁e ppa di ▁padam ▁pud ikk anam ▁en tra th ▁x x bo s ▁vay as ukku ▁tha gu ndha ▁kel vi ▁ya ▁ke kka ▁sol</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>xxrep ▁6 ▁ y ▁ye ah ▁ but ▁ay tha ▁e z hu th u ▁mari ▁irukk ke y ▁x x bo s ▁mani ▁sir ▁com eb ack ▁tri ler ▁mas s ▁ver a ▁le val ▁x x bo s ▁ena ▁da ▁in tha ▁2 ▁min s ▁e h ▁f ull ▁ ah ▁pa ak a ▁mudi la ▁x x bo s ▁edu ku ▁dis like ▁pan r avan ▁el</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>ap en ▁x x bo s ▁re mak e ▁of ▁the ▁sho f il m ▁ke kka ▁be kka ▁ke kka ▁be kka ▁x x bo s ▁de a sar ▁on ly ▁dal ▁mo vi e ▁than ▁mas s ▁x x bo s ▁dis like s ▁pan rav ag a ▁ lam ▁na ada ga ▁ka ad hal ▁ku mbal s ▁ xxrep ▁4 ▁ . ▁x x bo s</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"WIKRRrup_4JM"},"source":["# data_lm.vocab.itos = data_lm.vocab.itos\n","learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.3, pretrained=False, model_dir = './Tamil/models/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WzNlOS5QAF3S","executionInfo":{"status":"ok","timestamp":1609744140658,"user_tz":-330,"elapsed":4347,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"589d08d6-33c5-4c15-ad62-c59c3a280326"},"source":["learn.load('best_model',with_opt=True, device=device)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LanguageLearner(data=TextLMDataBunch;\n","\n","Train: LabelList (35139 items)\n","x: LMTextList\n","▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on\n","y: LMLabelList\n",",,,,\n","Path: .;\n","\n","Valid: LabelList (4388 items)\n","x: LMTextList\n","▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁thenkashi ▁mawatam ▁nad ar ▁samudaya m ▁charpauk ▁va hat us,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁sicipu ▁ xxrep ▁5 ▁ . ▁melum ▁itu ▁bonthe ▁patippues ▁mik ▁avasium ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁c ros s ed ▁f ing ers\n","y: LMLabelList\n",",,,,\n","Path: .;\n","\n","Test: LabelList (4392 items)\n","x: LMTextList\n","▁x x bo s,▁x x bo s,▁x x bo s,▁x x bo s,▁x x bo s\n","y: EmptyLabelList\n",",,,,\n","Path: ., model=SequentialRNN(\n","  (0): AWD_LSTM(\n","    (encoder): Embedding(8000, 400, padding_idx=1)\n","    (encoder_dp): EmbeddingDropout(\n","      (emb): Embedding(8000, 400, padding_idx=1)\n","    )\n","    (rnns): ModuleList(\n","      (0): WeightDropout(\n","        (module): LSTM(400, 1152, batch_first=True)\n","      )\n","      (1): WeightDropout(\n","        (module): LSTM(1152, 1152, batch_first=True)\n","      )\n","      (2): WeightDropout(\n","        (module): LSTM(1152, 400, batch_first=True)\n","      )\n","    )\n","    (input_dp): RNNDropout()\n","    (hidden_dps): ModuleList(\n","      (0): RNNDropout()\n","      (1): RNNDropout()\n","      (2): RNNDropout()\n","    )\n","  )\n","  (1): LinearDecoder(\n","    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n","    (output_dp): RNNDropout()\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb4908f7378>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='./Tamil/models/', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n","learn: LanguageLearner(data=TextLMDataBunch;\n","\n","Train: LabelList (35139 items)\n","x: LMTextList\n","▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on\n","y: LMLabelList\n",",,,,\n","Path: .;\n","\n","Valid: LabelList (4388 items)\n","x: LMTextList\n","▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁thenkashi ▁mawatam ▁nad ar ▁samudaya m ▁charpauk ▁va hat us,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁sicipu ▁ xxrep ▁5 ▁ . ▁melum ▁itu ▁bonthe ▁patippues ▁mik ▁avasium ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁c ros s ed ▁f ing ers\n","y: LMLabelList\n",",,,,\n","Path: .;\n","\n","Test: LabelList (4392 items)\n","x: LMTextList\n","▁x x bo s,▁x x bo s,▁x x bo s,▁x x bo s,▁x x bo s\n","y: EmptyLabelList\n",",,,,\n","Path: ., model=SequentialRNN(\n","  (0): AWD_LSTM(\n","    (encoder): Embedding(8000, 400, padding_idx=1)\n","    (encoder_dp): EmbeddingDropout(\n","      (emb): Embedding(8000, 400, padding_idx=1)\n","    )\n","    (rnns): ModuleList(\n","      (0): WeightDropout(\n","        (module): LSTM(400, 1152, batch_first=True)\n","      )\n","      (1): WeightDropout(\n","        (module): LSTM(1152, 1152, batch_first=True)\n","      )\n","      (2): WeightDropout(\n","        (module): LSTM(1152, 400, batch_first=True)\n","      )\n","    )\n","    (input_dp): RNNDropout()\n","    (hidden_dps): ModuleList(\n","      (0): RNNDropout()\n","      (1): RNNDropout()\n","      (2): RNNDropout()\n","    )\n","  )\n","  (1): LinearDecoder(\n","    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n","    (output_dp): RNNDropout()\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fb4908f7378>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='./Tamil/models/', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): Embedding(8000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(8000, 400, padding_idx=1)\n","  )\n","  (2): LinearDecoder(\n","    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n","    (output_dp): RNNDropout()\n","  )\n",")], add_time=True, silent=False)\n","alpha: 2.0\n","beta: 1.0], layer_groups=[Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): Embedding(8000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(8000, 400, padding_idx=1)\n","  )\n","  (2): LinearDecoder(\n","    (decoder): Linear(in_features=400, out_features=8000, bias=True)\n","    (output_dp): RNNDropout()\n","  )\n",")], add_time=True, silent=False)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"PzG9djXGBqxU"},"source":["learn.freeze()\n","learn.fit_one_cycle(1, 1e-2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g5HOPd44EvBh"},"source":["learn.save('fit_head', with_opt=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YAN9t8a-EzCe"},"source":["learn.load('fit_head', with_opt=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"vBMtNXPYEB7v","executionInfo":{"status":"ok","timestamp":1609741760682,"user_tz":-330,"elapsed":288225,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"c775ab4e-5b24-4bb3-cb11-4dd39e02267d"},"source":["learn.unfreeze()\n","learn.fit_one_cycle(5, 1e-3)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>3.764874</td>\n","      <td>3.689709</td>\n","      <td>0.376600</td>\n","      <td>00:57</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>3.481884</td>\n","      <td>3.446873</td>\n","      <td>0.407493</td>\n","      <td>00:56</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>3.274419</td>\n","      <td>3.344945</td>\n","      <td>0.420268</td>\n","      <td>00:57</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>3.191977</td>\n","      <td>3.308245</td>\n","      <td>0.425670</td>\n","      <td>00:57</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>3.155731</td>\n","      <td>3.303349</td>\n","      <td>0.426064</td>\n","      <td>00:57</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"40z3K9gfEZJ7","executionInfo":{"status":"ok","timestamp":1609741762604,"user_tz":-330,"elapsed":262212,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"4467ec23-e2bd-461b-c46f-85c46c2dde81"},"source":["learn.save('fine_tuned', with_opt=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'en payar ▁count arai ▁samudaya m ▁charpauk ▁kull ull ▁devar attam ▁ippattin'"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"LUtl2HLXE0eN","executionInfo":{"status":"ok","timestamp":1609745649389,"user_tz":-330,"elapsed":6679,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"f07cafcd-941a-42e7-b57d-ab3b45d1fd48"},"source":["learn.load('fine_tuned', with_opt=True);\n","learn.predict('en payar',n_words=10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'en payar ▁ke dai dra v aiye ▁cholli va ndar o ▁ange'"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"J6pJfDbrEf-7"},"source":["learn.save_encoder('fine_tuned_enc')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wiKClTDPTtf3"},"source":["def change_1h_targ(targ):\n","    n = len(data.label_dict)\n","    ohe = [0]*n\n","    ohe[targ] = 1\n","    return ohe"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZj31_CpTuCa"},"source":["data.train_df['ohe'] = data.train_df['label'].apply(change_1h_targ)\n","data.val_df['ohe'] = data.val_df['label'].apply(change_1h_targ)\n","label_cols = ['label']\n","text_cols = ['input']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"ZoOcu_6HUPV6","executionInfo":{"status":"ok","timestamp":1609747610666,"user_tz":-330,"elapsed":1194,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"4edb2f64-6889-4011-a677-3843cd2a0cc2"},"source":["data.train_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>label</th>\n","      <th>ohe</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>movie vara level la Erika poguthu</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n","      <td>1</td>\n","      <td>[0, 1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Padam nalla comedy padama irukum polaye..</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>karthick subburaj anne .... intha padam vetri ...</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>counter devar.charpauk vellri peni vahatus lion</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>35134</th>\n","      <td>Trending number #2 idhukku nammalam karanamnu ...</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>35135</th>\n","      <td>Movie script super, athuvum HIP HOP Tamizha mu...</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>35136</th>\n","      <td>Just 3k likes for 300k likes</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>35137</th>\n","      <td>Aaloo le lo. Kanda le lo.</td>\n","      <td>1</td>\n","      <td>[0, 1, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>35138</th>\n","      <td>namacal mawatam  vannier charpauk tiraupati pa...</td>\n","      <td>0</td>\n","      <td>[1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>35139 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                   input  ...                 ohe\n","0                      movie vara level la Erika poguthu  ...  [1, 0, 0, 0, 0, 0]\n","1      I love Ajith Kumar Vivegam movie inki mjy bht ...  ...  [0, 1, 0, 0, 0, 0]\n","2              Padam nalla comedy padama irukum polaye..  ...  [1, 0, 0, 0, 0, 0]\n","3      karthick subburaj anne .... intha padam vetri ...  ...  [1, 0, 0, 0, 0, 0]\n","4        counter devar.charpauk vellri peni vahatus lion  ...  [1, 0, 0, 0, 0, 0]\n","...                                                  ...  ...                 ...\n","35134  Trending number #2 idhukku nammalam karanamnu ...  ...  [1, 0, 0, 0, 0, 0]\n","35135  Movie script super, athuvum HIP HOP Tamizha mu...  ...  [1, 0, 0, 0, 0, 0]\n","35136                       Just 3k likes for 300k likes  ...  [1, 0, 0, 0, 0, 0]\n","35137                          Aaloo le lo. Kanda le lo.  ...  [0, 1, 0, 0, 0, 0]\n","35138  namacal mawatam  vannier charpauk tiraupati pa...  ...  [1, 0, 0, 0, 0, 0]\n","\n","[35139 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"jUI0HIblOoAx","executionInfo":{"status":"ok","timestamp":1610649341298,"user_tz":-330,"elapsed":78904,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"ba599e66-843d-4a19-d428-411785b18aa4"},"source":["data_clas = TextClasDataBunch.from_df(path=path, train_df=data.train_df, valid_df=data.val_df, test_df = data.test_df, tokenizer=tokenizer, vocab=taen_vocab, bs=16, label_cols = label_cols, text_cols=text_cols)\n","data_clas.show_batch()"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return np.array(a, dtype=dtype, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>▁x x bo s ▁tira u pati ▁ xxrep ▁10 ▁= ▁mann es ▁penn es ▁ka kk ▁vant ▁ nayaki ▁ xxrep ▁4 ▁ . ▁naatak ▁kadal ai ▁tol ur ikum ▁navina ▁tira u pati ▁ xxrep ▁5 ▁ . ▁pin chil ▁badutt a ▁we m pi ▁than ▁vat um ▁nan jai ▁suva ittal ▁maranam ▁than ▁min ch m ▁ xxrep ▁5 ▁ . ▁per si var uku ▁than ▁theri</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <td>▁x x bo s ▁10 ▁( aver ag e ) ▁pon n ung ▁viddu ku ▁na ck y ▁ton k ▁botu ttu ▁ivan uk ▁pon tu , ▁aval u galum ▁sir ie ▁sing ari ch ittu ▁10 ▁ambal ing ▁munn adi ▁foi ▁bo se ▁tar itu . ▁ivan uk ▁evvalou ▁var ad t chan ai ▁taruv anu ▁kat k antu ▁aval uk ▁evvalou ▁syettu ▁va chir ukkan ▁ / ▁chamba</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <td>▁x x bo s ▁it ▁ot uki du ▁vill uppu nar u ▁padam ▁kadu etty ar ▁dam pia ▁ka kar om ▁varu ngal adu l ▁edu ng ▁arasu ▁turai l ▁vanni er ▁devar ▁ka un der ▁vell aur ▁yadav ar ▁chett ar nu ▁nu ▁ell ▁samudaya mum ▁bu lli nga ▁pati kk il tu l ▁irundhu ▁ella du kum ▁poor vi k ▁chott ▁vi c rom ▁nam ▁vari ppan m</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>▁x x bo s ▁0 : 59 ▁un k n ow n ▁ num ber ▁ ; ▁en da ▁manda ya ▁mara ch een ga ▁konda ya ▁mara ▁che e ngal a ; ▁ num ber ▁is ▁vis i ble ▁ro l ling ▁on ▁the ▁flo or ▁la u gh ing ▁ro l ling ▁on ▁the ▁flo or ▁la u gh ing ▁ro l ling ▁on ▁the ▁flo or ▁la</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <td>▁x x bo s ▁than ks ▁pa ▁in tham ari ▁padam ▁edu th ath ukku ▁nam m ave ttu ▁pilla i gal ukku ▁eth u ▁oru ▁se ma ▁padam ▁ , ath uv um ▁ant ha ▁inter vi e w ▁la ▁son ning a ▁paru nga ▁the ater ▁la ▁po i ▁par ung anu ▁solla ▁do w n lo ad ▁pann iya ch um ▁par ung anu ▁se ma ▁pa</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rSXW6ybGE66w","executionInfo":{"status":"ok","timestamp":1610649342592,"user_tz":-330,"elapsed":78624,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"0ef43060-b359-4dd6-98fa-6250432c2b1a"},"source":["data_clas.sanity_check()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"M-MUrIhoE8zx","executionInfo":{"status":"ok","timestamp":1610649351112,"user_tz":-330,"elapsed":8506,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"38acc0cb-1aca-451d-c8a4-a465ccb2a84b"},"source":["learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5, model_dir = './Tamil/models')\n","learn.load_encoder('fine_tuned_enc')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["RNNLearner(data=TextClasDataBunch;\n","\n","Train: LabelList (35139 items)\n","x: TextList\n","▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on\n","y: CategoryList\n","0,1,0,0,0\n","Path: .;\n","\n","Valid: LabelList (4388 items)\n","x: TextList\n","▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁thenkashi ▁mawatam ▁nad ar ▁samudaya m ▁charpauk ▁va hat us,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁sicipu ▁ xxrep ▁5 ▁ . ▁melum ▁itu ▁bonthe ▁patippues ▁mik ▁avasium ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁c ros s ed ▁f ing ers\n","y: CategoryList\n","0,0,1,0,0\n","Path: .;\n","\n","Test: LabelList (4392 items)\n","x: TextList\n","▁x x bo s ▁14 . 12 . 20 18 ▁e po ▁tra il er ▁pat hu tu ▁ir ken ▁ . . . ▁se may a ▁iru ku,▁x x bo s ▁pa ka ▁than a ▁por o ▁mo vi e ▁la ▁enna ▁iru ku nu,▁x x bo s ▁“ u ▁ken a ▁t ung gu ▁le bi h ▁la ma ▁la gi ▁un tu k ▁ ta hu ▁say a ” ▁- ▁chi ya an ▁re co g ni z ed,▁x x bo s ▁su riya ▁anna ▁ver a ▁le vel ▁anna ▁mas s,▁x x bo s ▁su ma ▁kath tha ath a ▁da ▁so und ▁over ▁a ▁poo da ▁kud a ath u ▁pa ▁s 3 ▁1 ▁mon th ▁ oda ▁ sto p ▁a ak id um ▁the n ▁bair ava a ▁da ▁aa dd chi ▁than ▁kath thi ▁kath thi ▁tho nda iya ▁kil ika tha ▁pa\n","y: EmptyLabelList\n",",,,,\n","Path: ., model=SequentialRNN(\n","  (0): MultiBatchEncoder(\n","    (module): AWD_LSTM(\n","      (encoder): Embedding(8000, 400, padding_idx=1)\n","      (encoder_dp): EmbeddingDropout(\n","        (emb): Embedding(8000, 400, padding_idx=1)\n","      )\n","      (rnns): ModuleList(\n","        (0): WeightDropout(\n","          (module): LSTM(400, 1152, batch_first=True)\n","        )\n","        (1): WeightDropout(\n","          (module): LSTM(1152, 1152, batch_first=True)\n","        )\n","        (2): WeightDropout(\n","          (module): LSTM(1152, 400, batch_first=True)\n","        )\n","      )\n","      (input_dp): RNNDropout()\n","      (hidden_dps): ModuleList(\n","        (0): RNNDropout()\n","        (1): RNNDropout()\n","        (2): RNNDropout()\n","      )\n","    )\n","  )\n","  (1): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f4fcd455510>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='./Tamil/models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n","learn: RNNLearner(data=TextClasDataBunch;\n","\n","Train: LabelList (35139 items)\n","x: TextList\n","▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on\n","y: CategoryList\n","0,1,0,0,0\n","Path: .;\n","\n","Valid: LabelList (4388 items)\n","x: TextList\n","▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁thenkashi ▁mawatam ▁nad ar ▁samudaya m ▁charpauk ▁va hat us,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁sicipu ▁ xxrep ▁5 ▁ . ▁melum ▁itu ▁bonthe ▁patippues ▁mik ▁avasium ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁c ros s ed ▁f ing ers\n","y: CategoryList\n","0,0,1,0,0\n","Path: .;\n","\n","Test: LabelList (4392 items)\n","x: TextList\n","▁x x bo s ▁14 . 12 . 20 18 ▁e po ▁tra il er ▁pat hu tu ▁ir ken ▁ . . . ▁se may a ▁iru ku,▁x x bo s ▁pa ka ▁than a ▁por o ▁mo vi e ▁la ▁enna ▁iru ku nu,▁x x bo s ▁“ u ▁ken a ▁t ung gu ▁le bi h ▁la ma ▁la gi ▁un tu k ▁ ta hu ▁say a ” ▁- ▁chi ya an ▁re co g ni z ed,▁x x bo s ▁su riya ▁anna ▁ver a ▁le vel ▁anna ▁mas s,▁x x bo s ▁su ma ▁kath tha ath a ▁da ▁so und ▁over ▁a ▁poo da ▁kud a ath u ▁pa ▁s 3 ▁1 ▁mon th ▁ oda ▁ sto p ▁a ak id um ▁the n ▁bair ava a ▁da ▁aa dd chi ▁than ▁kath thi ▁kath thi ▁tho nda iya ▁kil ika tha ▁pa\n","y: EmptyLabelList\n",",,,,\n","Path: ., model=SequentialRNN(\n","  (0): MultiBatchEncoder(\n","    (module): AWD_LSTM(\n","      (encoder): Embedding(8000, 400, padding_idx=1)\n","      (encoder_dp): EmbeddingDropout(\n","        (emb): Embedding(8000, 400, padding_idx=1)\n","      )\n","      (rnns): ModuleList(\n","        (0): WeightDropout(\n","          (module): LSTM(400, 1152, batch_first=True)\n","        )\n","        (1): WeightDropout(\n","          (module): LSTM(1152, 1152, batch_first=True)\n","        )\n","        (2): WeightDropout(\n","          (module): LSTM(1152, 400, batch_first=True)\n","        )\n","      )\n","      (input_dp): RNNDropout()\n","      (hidden_dps): ModuleList(\n","        (0): RNNDropout()\n","        (1): RNNDropout()\n","        (2): RNNDropout()\n","      )\n","    )\n","  )\n","  (1): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f4fcd455510>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='./Tamil/models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n","  (0): Embedding(8000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(8000, 400, padding_idx=1)\n","  )\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n",")], add_time=True, silent=False)\n","alpha: 2.0\n","beta: 1.0], layer_groups=[Sequential(\n","  (0): Embedding(8000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(8000, 400, padding_idx=1)\n","  )\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n",")], add_time=True, silent=False)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x0Jo5ysMFXxM","executionInfo":{"status":"ok","timestamp":1610133404020,"user_tz":-330,"elapsed":262637,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"6c7cb367-f382-4305-d22d-fccb382cb583"},"source":["learn.freeze()\n","learn.loss_func.func"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CrossEntropyLoss()"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"dcCpuW8xL0ea"},"source":["f1 = FBeta(beta = 1,average = 'weighted')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8cf8KbIXGQ4T"},"source":["learn.metrics = [f1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":154},"id":"E675HGy1GYtP","executionInfo":{"status":"ok","timestamp":1610133477007,"user_tz":-330,"elapsed":48258,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"018acc48-ecc4-4b96-81e8-16988a870042"},"source":["learn.fit_one_cycle(1, 1e-2)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>f_beta</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.809048</td>\n","      <td>0.735917</td>\n","      <td>0.676067</td>\n","      <td>00:47</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"1rzzn8KWHfX9"},"source":["learn.save('first-full')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5WTHl-cuGayQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609747881627,"user_tz":-330,"elapsed":1681,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"681b4ea1-e776-4899-c757-7d64a8a16792"},"source":["learn.load('first-full')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNLearner(data=TextClasDataBunch;\n","\n","Train: LabelList (35139 items)\n","x: TextList\n","▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on\n","y: CategoryList\n","0,1,0,0,0\n","Path: .;\n","\n","Valid: LabelList (4388 items)\n","x: TextList\n","▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁thenkashi ▁mawatam ▁nad ar ▁samudaya m ▁charpauk ▁va hat us,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁sicipu ▁ xxrep ▁5 ▁ . ▁melum ▁itu ▁bonthe ▁patippues ▁mik ▁avasium ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁c ros s ed ▁f ing ers\n","y: CategoryList\n","0,0,1,0,0\n","Path: .;\n","\n","Test: LabelList (4392 items)\n","x: TextList\n","▁x x bo s ▁14 . 12 . 20 18 ▁e po ▁tra il er ▁pat hu tu ▁ir ken ▁ . . . ▁se may a ▁iru ku,▁x x bo s ▁pa ka ▁than a ▁por o ▁mo vi e ▁la ▁enna ▁iru ku nu,▁x x bo s ▁“ u ▁ken a ▁t ung gu ▁le bi h ▁la ma ▁la gi ▁un tu k ▁ ta hu ▁say a ” ▁- ▁chi ya an ▁re co g ni z ed,▁x x bo s ▁su riya ▁anna ▁ver a ▁le vel ▁anna ▁mas s,▁x x bo s ▁su ma ▁kath tha ath a ▁da ▁so und ▁over ▁a ▁poo da ▁kud a ath u ▁pa ▁s 3 ▁1 ▁mon th ▁ oda ▁ sto p ▁a ak id um ▁the n ▁bair ava a ▁da ▁aa dd chi ▁than ▁kath thi ▁kath thi ▁tho nda iya ▁kil ika tha ▁pa\n","y: EmptyLabelList\n",",,,,\n","Path: ., model=SequentialRNN(\n","  (0): MultiBatchEncoder(\n","    (module): AWD_LSTM(\n","      (encoder): Embedding(8000, 400, padding_idx=1)\n","      (encoder_dp): EmbeddingDropout(\n","        (emb): Embedding(8000, 400, padding_idx=1)\n","      )\n","      (rnns): ModuleList(\n","        (0): WeightDropout(\n","          (module): LSTM(400, 1152, batch_first=True)\n","        )\n","        (1): WeightDropout(\n","          (module): LSTM(1152, 1152, batch_first=True)\n","        )\n","        (2): WeightDropout(\n","          (module): LSTM(1152, 400, batch_first=True)\n","        )\n","      )\n","      (input_dp): RNNDropout()\n","      (hidden_dps): ModuleList(\n","        (0): RNNDropout()\n","        (1): RNNDropout()\n","        (2): RNNDropout()\n","      )\n","    )\n","  )\n","  (1): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[FBeta(average='weighted', pos_label=1, eps=1e-09, beta=1)], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='./Tamil/models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n","learn: RNNLearner(data=TextClasDataBunch;\n","\n","Train: LabelList (35139 items)\n","x: TextList\n","▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on\n","y: CategoryList\n","0,1,0,0,0\n","Path: .;\n","\n","Valid: LabelList (4388 items)\n","x: TextList\n","▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁thenkashi ▁mawatam ▁nad ar ▁samudaya m ▁charpauk ▁va hat us,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁sicipu ▁ xxrep ▁5 ▁ . ▁melum ▁itu ▁bonthe ▁patippues ▁mik ▁avasium ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁c ros s ed ▁f ing ers\n","y: CategoryList\n","0,0,1,0,0\n","Path: .;\n","\n","Test: LabelList (4392 items)\n","x: TextList\n","▁x x bo s ▁14 . 12 . 20 18 ▁e po ▁tra il er ▁pat hu tu ▁ir ken ▁ . . . ▁se may a ▁iru ku,▁x x bo s ▁pa ka ▁than a ▁por o ▁mo vi e ▁la ▁enna ▁iru ku nu,▁x x bo s ▁“ u ▁ken a ▁t ung gu ▁le bi h ▁la ma ▁la gi ▁un tu k ▁ ta hu ▁say a ” ▁- ▁chi ya an ▁re co g ni z ed,▁x x bo s ▁su riya ▁anna ▁ver a ▁le vel ▁anna ▁mas s,▁x x bo s ▁su ma ▁kath tha ath a ▁da ▁so und ▁over ▁a ▁poo da ▁kud a ath u ▁pa ▁s 3 ▁1 ▁mon th ▁ oda ▁ sto p ▁a ak id um ▁the n ▁bair ava a ▁da ▁aa dd chi ▁than ▁kath thi ▁kath thi ▁tho nda iya ▁kil ika tha ▁pa\n","y: EmptyLabelList\n",",,,,\n","Path: ., model=SequentialRNN(\n","  (0): MultiBatchEncoder(\n","    (module): AWD_LSTM(\n","      (encoder): Embedding(8000, 400, padding_idx=1)\n","      (encoder_dp): EmbeddingDropout(\n","        (emb): Embedding(8000, 400, padding_idx=1)\n","      )\n","      (rnns): ModuleList(\n","        (0): WeightDropout(\n","          (module): LSTM(400, 1152, batch_first=True)\n","        )\n","        (1): WeightDropout(\n","          (module): LSTM(1152, 1152, batch_first=True)\n","        )\n","        (2): WeightDropout(\n","          (module): LSTM(1152, 400, batch_first=True)\n","        )\n","      )\n","      (input_dp): RNNDropout()\n","      (hidden_dps): ModuleList(\n","        (0): RNNDropout()\n","        (1): RNNDropout()\n","        (2): RNNDropout()\n","      )\n","    )\n","  )\n","  (1): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[FBeta(average='weighted', pos_label=1, eps=1e-09, beta=1)], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='./Tamil/models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n","  (0): Embedding(8000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(8000, 400, padding_idx=1)\n","  )\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n",")], add_time=True, silent=False)\n","alpha: 2.0\n","beta: 1.0], layer_groups=[Sequential(\n","  (0): Embedding(8000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(8000, 400, padding_idx=1)\n","  )\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n",")], add_time=True, silent=False)"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"-3gFAnDlHlcM","colab":{"base_uri":"https://localhost:8080/","height":154},"executionInfo":{"status":"ok","timestamp":1609747938152,"user_tz":-330,"elapsed":57366,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"13375cbe-ff1c-4499-ff8a-e194ae310d30"},"source":["learn.freeze_to(-2)\n","learn.fit_one_cycle(1, 1e-2)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>f_beta</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.721922</td>\n","      <td>0.672188</td>\n","      <td>0.718449</td>\n","      <td>00:55</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"L-qSgMgOWnAq"},"source":["learn.save('second-full')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZ6truM6gGcC","executionInfo":{"status":"ok","timestamp":1610133897820,"user_tz":-330,"elapsed":987,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"619de86d-c6c6-4e66-d478-f7b8a010fb01"},"source":["learn.load('second-full')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNLearner(data=TextClasDataBunch;\n","\n","Train: LabelList (35139 items)\n","x: TextList\n","▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on\n","y: CategoryList\n","0,1,0,0,0\n","Path: .;\n","\n","Valid: LabelList (4388 items)\n","x: TextList\n","▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁thenkashi ▁mawatam ▁nad ar ▁samudaya m ▁charpauk ▁va hat us,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁sicipu ▁ xxrep ▁5 ▁ . ▁melum ▁itu ▁bonthe ▁patippues ▁mik ▁avasium ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁c ros s ed ▁f ing ers\n","y: CategoryList\n","0,0,1,0,0\n","Path: .;\n","\n","Test: LabelList (4392 items)\n","x: TextList\n","▁x x bo s ▁14 . 12 . 20 18 ▁e po ▁tra il er ▁pat hu tu ▁ir ken ▁ . . . ▁se may a ▁iru ku,▁x x bo s ▁pa ka ▁than a ▁por o ▁mo vi e ▁la ▁enna ▁iru ku nu,▁x x bo s ▁“ u ▁ken a ▁t ung gu ▁le bi h ▁la ma ▁la gi ▁un tu k ▁ ta hu ▁say a ” ▁- ▁chi ya an ▁re co g ni z ed,▁x x bo s ▁su riya ▁anna ▁ver a ▁le vel ▁anna ▁mas s,▁x x bo s ▁su ma ▁kath tha ath a ▁da ▁so und ▁over ▁a ▁poo da ▁kud a ath u ▁pa ▁s 3 ▁1 ▁mon th ▁ oda ▁ sto p ▁a ak id um ▁the n ▁bair ava a ▁da ▁aa dd chi ▁than ▁kath thi ▁kath thi ▁tho nda iya ▁kil ika tha ▁pa\n","y: EmptyLabelList\n",",,,,\n","Path: ., model=SequentialRNN(\n","  (0): MultiBatchEncoder(\n","    (module): AWD_LSTM(\n","      (encoder): Embedding(8000, 400, padding_idx=1)\n","      (encoder_dp): EmbeddingDropout(\n","        (emb): Embedding(8000, 400, padding_idx=1)\n","      )\n","      (rnns): ModuleList(\n","        (0): WeightDropout(\n","          (module): LSTM(400, 1152, batch_first=True)\n","        )\n","        (1): WeightDropout(\n","          (module): LSTM(1152, 1152, batch_first=True)\n","        )\n","        (2): WeightDropout(\n","          (module): LSTM(1152, 400, batch_first=True)\n","        )\n","      )\n","      (input_dp): RNNDropout()\n","      (hidden_dps): ModuleList(\n","        (0): RNNDropout()\n","        (1): RNNDropout()\n","        (2): RNNDropout()\n","      )\n","    )\n","  )\n","  (1): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[FBeta(average='weighted', pos_label=1, eps=1e-09, beta=1)], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='./Tamil/models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n","learn: RNNLearner(data=TextClasDataBunch;\n","\n","Train: LabelList (35139 items)\n","x: TextList\n","▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on\n","y: CategoryList\n","0,1,0,0,0\n","Path: .;\n","\n","Valid: LabelList (4388 items)\n","x: TextList\n","▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁thenkashi ▁mawatam ▁nad ar ▁samudaya m ▁charpauk ▁va hat us,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁sicipu ▁ xxrep ▁5 ▁ . ▁melum ▁itu ▁bonthe ▁patippues ▁mik ▁avasium ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁c ros s ed ▁f ing ers\n","y: CategoryList\n","0,0,1,0,0\n","Path: .;\n","\n","Test: LabelList (4392 items)\n","x: TextList\n","▁x x bo s ▁14 . 12 . 20 18 ▁e po ▁tra il er ▁pat hu tu ▁ir ken ▁ . . . ▁se may a ▁iru ku,▁x x bo s ▁pa ka ▁than a ▁por o ▁mo vi e ▁la ▁enna ▁iru ku nu,▁x x bo s ▁“ u ▁ken a ▁t ung gu ▁le bi h ▁la ma ▁la gi ▁un tu k ▁ ta hu ▁say a ” ▁- ▁chi ya an ▁re co g ni z ed,▁x x bo s ▁su riya ▁anna ▁ver a ▁le vel ▁anna ▁mas s,▁x x bo s ▁su ma ▁kath tha ath a ▁da ▁so und ▁over ▁a ▁poo da ▁kud a ath u ▁pa ▁s 3 ▁1 ▁mon th ▁ oda ▁ sto p ▁a ak id um ▁the n ▁bair ava a ▁da ▁aa dd chi ▁than ▁kath thi ▁kath thi ▁tho nda iya ▁kil ika tha ▁pa\n","y: EmptyLabelList\n",",,,,\n","Path: ., model=SequentialRNN(\n","  (0): MultiBatchEncoder(\n","    (module): AWD_LSTM(\n","      (encoder): Embedding(8000, 400, padding_idx=1)\n","      (encoder_dp): EmbeddingDropout(\n","        (emb): Embedding(8000, 400, padding_idx=1)\n","      )\n","      (rnns): ModuleList(\n","        (0): WeightDropout(\n","          (module): LSTM(400, 1152, batch_first=True)\n","        )\n","        (1): WeightDropout(\n","          (module): LSTM(1152, 1152, batch_first=True)\n","        )\n","        (2): WeightDropout(\n","          (module): LSTM(1152, 400, batch_first=True)\n","        )\n","      )\n","      (input_dp): RNNDropout()\n","      (hidden_dps): ModuleList(\n","        (0): RNNDropout()\n","        (1): RNNDropout()\n","        (2): RNNDropout()\n","      )\n","    )\n","  )\n","  (1): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[FBeta(average='weighted', pos_label=1, eps=1e-09, beta=1)], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='./Tamil/models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n","  (0): Embedding(8000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(8000, 400, padding_idx=1)\n","  )\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n",")], add_time=True, silent=False)\n","alpha: 2.0\n","beta: 1.0], layer_groups=[Sequential(\n","  (0): Embedding(8000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(8000, 400, padding_idx=1)\n","  )\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n",")], add_time=True, silent=False)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":566},"id":"Ze7xXxQ1Woqs","executionInfo":{"status":"ok","timestamp":1610134480603,"user_tz":-330,"elapsed":581940,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"24ebf599-633e-434d-8f0a-a4f61ea2d7ae"},"source":["learn.unfreeze()\n","learn.fit_one_cycle(5, 1e-3, callbacks=[callbacks.SaveModelCallback(learn, every='improvement', monitor='f_beta', name='final')])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>f_beta</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.617821</td>\n","      <td>0.656613</td>\n","      <td>0.739116</td>\n","      <td>02:02</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.659365</td>\n","      <td>0.642266</td>\n","      <td>0.754676</td>\n","      <td>01:53</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.640485</td>\n","      <td>0.642448</td>\n","      <td>0.749290</td>\n","      <td>01:49</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.585432</td>\n","      <td>0.643950</td>\n","      <td>0.756755</td>\n","      <td>01:58</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.510516</td>\n","      <td>0.643676</td>\n","      <td>0.758727</td>\n","      <td>01:50</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["Better model found at epoch 0 with f_beta value: 0.7391160726547241.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["Better model found at epoch 1 with f_beta value: 0.7546758651733398.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["Better model found at epoch 3 with f_beta value: 0.7567550539970398.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n","<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["Better model found at epoch 4 with f_beta value: 0.7587268948554993.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDmnk9uIWr_4","executionInfo":{"status":"ok","timestamp":1610649355689,"user_tz":-330,"elapsed":13072,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"ea31ce7e-9396-41e4-ba0f-fd9004029db4"},"source":["learn.load('final')"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RNNLearner(data=TextClasDataBunch;\n","\n","Train: LabelList (35139 items)\n","x: TextList\n","▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on\n","y: CategoryList\n","0,1,0,0,0\n","Path: .;\n","\n","Valid: LabelList (4388 items)\n","x: TextList\n","▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁thenkashi ▁mawatam ▁nad ar ▁samudaya m ▁charpauk ▁va hat us,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁sicipu ▁ xxrep ▁5 ▁ . ▁melum ▁itu ▁bonthe ▁patippues ▁mik ▁avasium ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁c ros s ed ▁f ing ers\n","y: CategoryList\n","0,0,1,0,0\n","Path: .;\n","\n","Test: LabelList (4392 items)\n","x: TextList\n","▁x x bo s ▁14 . 12 . 20 18 ▁e po ▁tra il er ▁pat hu tu ▁ir ken ▁ . . . ▁se may a ▁iru ku,▁x x bo s ▁pa ka ▁than a ▁por o ▁mo vi e ▁la ▁enna ▁iru ku nu,▁x x bo s ▁“ u ▁ken a ▁t ung gu ▁le bi h ▁la ma ▁la gi ▁un tu k ▁ ta hu ▁say a ” ▁- ▁chi ya an ▁re co g ni z ed,▁x x bo s ▁su riya ▁anna ▁ver a ▁le vel ▁anna ▁mas s,▁x x bo s ▁su ma ▁kath tha ath a ▁da ▁so und ▁over ▁a ▁poo da ▁kud a ath u ▁pa ▁s 3 ▁1 ▁mon th ▁ oda ▁ sto p ▁a ak id um ▁the n ▁bair ava a ▁da ▁aa dd chi ▁than ▁kath thi ▁kath thi ▁tho nda iya ▁kil ika tha ▁pa\n","y: EmptyLabelList\n",",,,,\n","Path: ., model=SequentialRNN(\n","  (0): MultiBatchEncoder(\n","    (module): AWD_LSTM(\n","      (encoder): Embedding(8000, 400, padding_idx=1)\n","      (encoder_dp): EmbeddingDropout(\n","        (emb): Embedding(8000, 400, padding_idx=1)\n","      )\n","      (rnns): ModuleList(\n","        (0): WeightDropout(\n","          (module): LSTM(400, 1152, batch_first=True)\n","        )\n","        (1): WeightDropout(\n","          (module): LSTM(1152, 1152, batch_first=True)\n","        )\n","        (2): WeightDropout(\n","          (module): LSTM(1152, 400, batch_first=True)\n","        )\n","      )\n","      (input_dp): RNNDropout()\n","      (hidden_dps): ModuleList(\n","        (0): RNNDropout()\n","        (1): RNNDropout()\n","        (2): RNNDropout()\n","      )\n","    )\n","  )\n","  (1): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f4fcd455510>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='./Tamil/models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n","learn: RNNLearner(data=TextClasDataBunch;\n","\n","Train: LabelList (35139 items)\n","x: TextList\n","▁x x bo s ▁mo vi e ▁var a ▁le vel ▁la ▁eri ka ▁po gu th u,▁x x bo s ▁i ▁lo ve ▁aj ith ▁kumar ▁viv e gam ▁mo vi e ▁in ki ▁m j y ▁ bh t ▁achi ▁l gi,▁x x bo s ▁padam ▁nall a ▁com ed y ▁padam a ▁iru kum ▁pol aye . .,▁x x bo s ▁kar thi ck ▁su bbu raj ▁ann e ▁ xxrep ▁4 ▁ . ▁in tha ▁padam ▁ve tri ▁ada ya ▁un a gal ukku ▁en n uda ya ▁val th ukk al . . .,▁x x bo s ▁count er ▁devar . char pa uk ▁vellri ▁peni ▁va hat us ▁li on\n","y: CategoryList\n","0,1,0,0,0\n","Path: .;\n","\n","Valid: LabelList (4388 items)\n","x: TextList\n","▁x x bo s ▁han ds ome ▁hu n k ▁ke ri ▁va a ▁tha lai va a,▁x x bo s ▁thenkashi ▁mawatam ▁nad ar ▁samudaya m ▁charpauk ▁va hat us,▁x x bo s ▁je ▁ vo us ▁ai me ▁br avo ▁po ur ▁cli p ▁de ▁mer de ▁qu e ▁j ▁ xxunk co u te ▁au ▁to il ette .,▁x x bo s ▁sicipu ▁ xxrep ▁5 ▁ . ▁melum ▁itu ▁bonthe ▁patippues ▁mik ▁avasium ▁ xxrep ▁4 ▁ .,▁x x bo s ▁ver a ▁le vel ▁b g m ▁ . . ▁se m ma ▁tra il er . ▁c ros s ed ▁f ing ers\n","y: CategoryList\n","0,0,1,0,0\n","Path: .;\n","\n","Test: LabelList (4392 items)\n","x: TextList\n","▁x x bo s ▁14 . 12 . 20 18 ▁e po ▁tra il er ▁pat hu tu ▁ir ken ▁ . . . ▁se may a ▁iru ku,▁x x bo s ▁pa ka ▁than a ▁por o ▁mo vi e ▁la ▁enna ▁iru ku nu,▁x x bo s ▁“ u ▁ken a ▁t ung gu ▁le bi h ▁la ma ▁la gi ▁un tu k ▁ ta hu ▁say a ” ▁- ▁chi ya an ▁re co g ni z ed,▁x x bo s ▁su riya ▁anna ▁ver a ▁le vel ▁anna ▁mas s,▁x x bo s ▁su ma ▁kath tha ath a ▁da ▁so und ▁over ▁a ▁poo da ▁kud a ath u ▁pa ▁s 3 ▁1 ▁mon th ▁ oda ▁ sto p ▁a ak id um ▁the n ▁bair ava a ▁da ▁aa dd chi ▁than ▁kath thi ▁kath thi ▁tho nda iya ▁kil ika tha ▁pa\n","y: EmptyLabelList\n",",,,,\n","Path: ., model=SequentialRNN(\n","  (0): MultiBatchEncoder(\n","    (module): AWD_LSTM(\n","      (encoder): Embedding(8000, 400, padding_idx=1)\n","      (encoder_dp): EmbeddingDropout(\n","        (emb): Embedding(8000, 400, padding_idx=1)\n","      )\n","      (rnns): ModuleList(\n","        (0): WeightDropout(\n","          (module): LSTM(400, 1152, batch_first=True)\n","        )\n","        (1): WeightDropout(\n","          (module): LSTM(1152, 1152, batch_first=True)\n","        )\n","        (2): WeightDropout(\n","          (module): LSTM(1152, 400, batch_first=True)\n","        )\n","      )\n","      (input_dp): RNNDropout()\n","      (hidden_dps): ModuleList(\n","        (0): RNNDropout()\n","        (1): RNNDropout()\n","        (2): RNNDropout()\n","      )\n","    )\n","  )\n","  (1): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n","), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f4fcd455510>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='./Tamil/models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n","  (0): Embedding(8000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(8000, 400, padding_idx=1)\n","  )\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n",")], add_time=True, silent=False)\n","alpha: 2.0\n","beta: 1.0], layer_groups=[Sequential(\n","  (0): Embedding(8000, 400, padding_idx=1)\n","  (1): EmbeddingDropout(\n","    (emb): Embedding(8000, 400, padding_idx=1)\n","  )\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(400, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 1152, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): WeightDropout(\n","    (module): LSTM(1152, 400, batch_first=True)\n","  )\n","  (1): RNNDropout()\n","), Sequential(\n","  (0): PoolingLinearClassifier(\n","    (layers): Sequential(\n","      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): Dropout(p=0.2, inplace=False)\n","      (2): Linear(in_features=1200, out_features=50, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): Dropout(p=0.1, inplace=False)\n","      (6): Linear(in_features=50, out_features=6, bias=True)\n","    )\n","  )\n",")], add_time=True, silent=False)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"7RW6fEAcW26Z","executionInfo":{"status":"ok","timestamp":1610649359558,"user_tz":-330,"elapsed":16934,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"02e45dcb-18d5-42a8-f148-d6421814487f"},"source":["def get_predicted(preds):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    return pred_flat\n","\n","df_test = data.val_df.copy()\n","from sklearn.metrics import f1_score,accuracy_score\n","df_dict = {'query': list(df_test['input']), 'actual_label': list(df_test['label']), 'predicted_label': [0]*df_test.shape[0]}  \n","df_result = pd.DataFrame(df_dict)\n","preds = learn.get_preds(ds_type=DatasetType.Valid, ordered=True)\n","df_result['predicted_label'] = list(get_predicted(np.array(preds[0])))\n","df_result.head()"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query</th>\n","      <th>actual_label</th>\n","      <th>predicted_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Handsome hunk  keri vaa thalaivaa</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>thenkashi mawatam nadar samudayam charpauk vah...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>je vous aime bravo pour clip de merde que j éc...</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sicipu..... melum itu bonthe patippues mik ava...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Vera level BGM .. semma trailer. crossed fingers</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               query  ...  predicted_label\n","0                  Handsome hunk  keri vaa thalaivaa  ...                0\n","1  thenkashi mawatam nadar samudayam charpauk vah...  ...                0\n","2  je vous aime bravo pour clip de merde que j éc...  ...                1\n","3  sicipu..... melum itu bonthe patippues mik ava...  ...                0\n","4   Vera level BGM .. semma trailer. crossed fingers  ...                0\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnBfMgaPXLRW","executionInfo":{"status":"ok","timestamp":1610649359559,"user_tz":-330,"elapsed":16928,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"399a33eb-66f6-417a-cb47-238d59084c14"},"source":["f1_score(df_result['actual_label'], df_result['predicted_label'], average = 'weighted')"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7587268628954762"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"vJBfAvGwmHUf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610240363734,"user_tz":-330,"elapsed":1247,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"}},"outputId":"77920e0c-9571-4552-ac30-ff9063a8064a"},"source":["accuracy_score(df_result['actual_label'], df_result['predicted_label'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7830446672743847"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"YZ588U8OTEsh","executionInfo":{"status":"ok","timestamp":1610649374594,"user_tz":-330,"elapsed":8827,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"bfb3883d-cacd-49f0-ece4-7c5d0dbe3fb5"},"source":["logits = {}\n","preds = learn.get_preds(ds_type=DatasetType.Valid, ordered=True)\n","logits['val'] = preds[0]\n","preds = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n","logits['test'] = preds[0]"],"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":[""],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"xRQ5N1kalce_","executionInfo":{"status":"ok","timestamp":1610649374594,"user_tz":-330,"elapsed":8377,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["with open('tam_ulmfit_preds.pkl', 'wb') as f:\n","    pickle.dump(logits, f)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXR4wGNZluzm","executionInfo":{"status":"ok","timestamp":1610649374595,"user_tz":-330,"elapsed":7975,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}}},"source":["with open('tam_ulmfit_preds.pkl', 'rb') as f:\n","    dpred = pickle.load(f)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qowrhipnzi7-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610649374595,"user_tz":-330,"elapsed":6855,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"15395307286796798856"}},"outputId":"04963c21-a104-4c9b-8c96-fe0a67d4be0a"},"source":["dpred"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'test': tensor([[9.7739e-01, 1.2637e-05, 4.7476e-04, 1.6637e-03, 1.8689e-02, 1.7674e-03],\n","         [7.1744e-01, 1.3114e-04, 1.9899e-02, 4.1196e-02, 2.0459e-01, 1.6744e-02],\n","         [1.8518e-01, 8.1388e-01, 2.0480e-04, 1.8708e-04, 3.3984e-04, 2.0586e-04],\n","         ...,\n","         [3.7247e-01, 1.4980e-03, 3.5686e-02, 2.7768e-01, 2.8655e-01, 2.6119e-02],\n","         [7.2332e-01, 8.0857e-03, 1.4075e-02, 1.0035e-01, 2.9068e-02, 1.2511e-01],\n","         [7.6852e-02, 1.3278e-02, 5.5149e-02, 3.3028e-01, 3.0184e-01, 2.2260e-01]]),\n"," 'val': tensor([[9.4630e-01, 2.5260e-02, 2.2303e-03, 4.5569e-03, 1.7176e-02, 4.4743e-03],\n","         [9.9871e-01, 1.1815e-04, 7.0968e-05, 1.9295e-04, 5.7516e-04, 3.2838e-04],\n","         [1.1492e-01, 8.4584e-01, 3.3452e-03, 5.3570e-03, 1.2424e-02, 1.8113e-02],\n","         ...,\n","         [1.2351e-01, 3.7066e-03, 3.0324e-02, 3.9621e-01, 3.8728e-01, 5.8961e-02],\n","         [9.8717e-01, 4.8754e-03, 6.6320e-04, 2.3366e-03, 7.6715e-04, 4.1830e-03],\n","         [9.8976e-01, 2.5471e-04, 1.0145e-03, 1.1184e-03, 5.9199e-03, 1.9294e-03]])}"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"xnSqCETiLvRX"},"source":[""],"execution_count":null,"outputs":[]}]}