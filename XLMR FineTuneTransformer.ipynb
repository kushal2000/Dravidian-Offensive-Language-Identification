{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"XLMR FineTuneTransformer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-EFdQEJkl_P","executionInfo":{"status":"ok","timestamp":1610237536325,"user_tz":-330,"elapsed":23211,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"1e8fa619-f2a1-4498-f921-c072f9f700a4"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount = True)\n","import os\n","root_path = 'gdrive/My Drive/EACL/'\n","os.chdir(root_path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0n47rpqSqWne","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610237635669,"user_tz":-330,"elapsed":14308,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"fcbb9a75-7f7b-4fd5-c65e-f70492d49eb2"},"source":["!pip install sentencepiece==0.1.94\n","!pip install transformers==4.0.1\n","!pip install demoji\n","!pip install tweet-preprocessor\n","# !pip install transformers[sentencepiece]"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece==0.1.94\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\r\u001b[K     |▎                               | 10kB 26.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 16.0MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 14.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 13.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 9.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 9.6MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 10.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92kB 10.9MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122kB 8.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153kB 8.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 245kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 8.9MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.94\n","Collecting transformers==4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 7.5MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.1) (0.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.1) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.1) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.1) (3.0.12)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 24.3MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 29.2MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.1) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.1) (20.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.0.1) (1.19.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.1) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.0.1) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.1) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.1) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.0.1) (1.0.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.0.1) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=710df7783508556e5fd182fd47ef29f04d77624c553d9c15ddcbaf284f410466\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n","Collecting demoji\n","  Downloading https://files.pythonhosted.org/packages/88/6a/34379abe01c9c36fe9fddc4181dd935332e7d0159ec3fae76f712e49bcea/demoji-0.4.0-py2.py3-none-any.whl\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from demoji) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2020.12.5)\n","Installing collected packages: colorama, demoji\n","Successfully installed colorama-0.4.4 demoji-0.4.0\n","Collecting tweet-preprocessor\n","  Downloading https://files.pythonhosted.org/packages/17/9d/71bd016a9edcef8860c607e531f30bd09b13103c7951ae73dd2bf174163c/tweet_preprocessor-0.6.0-py3-none-any.whl\n","Installing collected packages: tweet-preprocessor\n","Successfully installed tweet-preprocessor-0.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9vOLxNuZlk4m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610237641596,"user_tz":-330,"elapsed":18245,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"83a4da6e-4c69-4a3e-bb11-3bf1410ed137"},"source":["import numpy as np\n","import pandas as pd\n","from transformers import AutoModel, AutoTokenizer\n","import torch.nn as nn\n","import torch\n","import copy\n","from transformers import BertModel, RobertaModel, BertTokenizer, RobertaTokenizer, AdamW, get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, random_split, DataLoader, IterableDataset, ConcatDataset\n","import sklearn\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.metrics import f1_score \n","from tqdm import tqdm\n","import demoji \n","import random\n","demoji.download_codes() \n","import preprocessor as p\n","p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED)\n","plt.rcParams['figure.figsize'] = [15, 8]\n","plt.rcParams.update({'font.size': 8})\n","RANDOM_SEED = 42\n","model_path = 'xlm-roberta-base'\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading emoji data ...\n","... OK (Got response in 0.19 seconds)\n","Writing emoji data to /root/.demoji/codes.json ...\n","... OK\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"72QHLh_2T-dA","executionInfo":{"status":"ok","timestamp":1610237641599,"user_tz":-330,"elapsed":5449,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}}},"source":["def random_seed(seed_value, use_cuda):\n","    np.random.seed(seed_value)  \n","    torch.manual_seed(seed_value)  \n","    random.seed(seed_value)\n","    if use_cuda:\n","        torch.cuda.manual_seed(seed_value)\n","        torch.cuda.manual_seed_all(seed_value)  \n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False\n","random_seed(RANDOM_SEED, True)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"9guszMAwpPeH","executionInfo":{"status":"ok","timestamp":1610238282910,"user_tz":-330,"elapsed":1093,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}}},"source":["hastags = []"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIOPL_OTrRy4","executionInfo":{"status":"ok","timestamp":1610238284744,"user_tz":-330,"elapsed":1604,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}}},"source":["class Dataset():\n","    def __init__(self, train_data, val_data, batch_size = 32):\n","        self.train_data = train_data\n","        self.val_data = val_data\n","        self.batch_size = batch_size\n","\n","        self.label_dict = {'Not_offensive': 0,\n","                            'Offensive_Targeted_Insult_Group': 4,\n","                            'Offensive_Targeted_Insult_Individual': 3,\n","                            'Offensive_Targeted_Insult_Other': 2,\n","                            'Offensive_Untargetede': 1,\n","                            'not-Tamil': 5}\n","                                    \n","        self.count_dic = {}\n","\n","        self.train_inputs, self.train_labels = self.process_data(self.train_data)\n","        self.val_inputs, self.val_labels = self.process_data(self.val_data)\n","        # count_dic = {}\n","        # for data in self.train_labels:\n","        #     label = int(data)\n","        #     count_dic[label] = count_dic.get(label, 0)+1\n","        # self.weights = torch.Tensor([len(self.train_labels)/count_dic[i] for i in range(2)]).to(device)\n","        self.train_dataloader = self.get_dataloader(self.train_inputs, self.train_labels)\n","        self.val_dataloader = self.get_dataloader(self.val_inputs, self. val_labels, train = False)\n","\n","    def tokenize(self, sentences, padding = True, max_len = 256):\n","        tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n","        input_ids, attention_masks = [], []\n","        for sent in sentences:\n","            encoded_dict = tokenizer.encode_plus(sent,\n","                                                    add_special_tokens=True,\n","                                                    max_length=max_len, \n","                                                    padding='max_length', \n","                                                    return_attention_mask = True,\n","                                                    return_tensors = 'pt', \n","                                                    truncation = True)\n","            input_ids.append(encoded_dict['input_ids'])\n","            attention_masks.append(encoded_dict['attention_mask'])\n","        \n","        input_ids = torch.cat(input_ids, dim=0)\n","        attention_masks = torch.cat(attention_masks, dim=0)\n","\n","        return {'input_ids': input_ids, 'attention_masks': attention_masks}\n","    \n","    def process_data(self, data):\n","        sentences, labels = [], []\n","        print(len(data))\n","        for line in data:\n","            sentence = line.strip().split('\\t')\n","            label = sentence.pop()\n","            # if label == 'not-Kannada': print(sentence)\n","            if label not in self.label_dict:\n","                self.label_dict[label] = len(self.label_dict)\n","            words = sentence\n","            for word in (' '.join(words)).split():\n","                if word[0]=='#': hastags.append(word)\n","            sentence = p.clean(' '.join(sentence)).replace('#','')\n","            emoji_dict = demoji.findall(sentence)\n","            if len(emoji_dict): \n","                for emoji, text in emoji_dict.items():\n","                    sentence = sentence.replace(emoji, ' '+text+' ')\n","                    sentence = ' '.join(sentence.split())\n","            sentences.append(sentence)\n","            labels.append(self.label_dict[label])\n","            # if label == 'not-malayalam': labels.append(1)\n","            # else: labels.append(0)\n","            self.count_dic[labels[-1]] = self.count_dic.get(labels[-1], 0) + 1\n","        inputs = self.tokenize(sentences)\n","\n","        return inputs, torch.Tensor(labels)\n","    \n","    def get_dataloader(self, inputs, labels, train = True):\n","        data = TensorDataset(inputs['input_ids'], inputs['attention_masks'], labels)\n","        if train:\n","            sampler = RandomSampler(data)\n","        else:\n","            sampler = SequentialSampler(data)\n","        return DataLoader(data, sampler=sampler, batch_size=self.batch_size)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"0HBnekZFnnhe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610238290623,"user_tz":-330,"elapsed":6560,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"56d067a1-6adb-40f5-ac70-c8ca3e39c584"},"source":["with open('Dataset/kannada_offensive_train.csv', 'r') as f:\n","    train_data = f.readlines()\n","with open('Dataset/kannada_offensive_dev.csv', 'r') as f:\n","    val_data = f.readlines()\n","data = Dataset(train_data, val_data)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["6217\n","777\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKVKxX4FpgTU","executionInfo":{"status":"ok","timestamp":1610238290626,"user_tz":-330,"elapsed":827,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"bf97cdfb-7fb8-4a3c-c41c-74c26507e061"},"source":["len(hastags)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["73"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ga18vKPlpY-z","executionInfo":{"status":"ok","timestamp":1610238294083,"user_tz":-330,"elapsed":1076,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"d710fd51-eb10-485c-9682-7cef0e1ae9b6"},"source":["\n","hastags"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['#',\n"," '#Who',\n"," '#drrajkumar',\n"," '#marakkar',\n"," '#1',\n"," '#ಇದು',\n"," '#ASN',\n"," '#handsup',\n"," '#RIP',\n"," '#ASN',\n"," '#ಕನ್ನಡಿಗರು',\n"," '#marakkar',\n"," '#person',\n"," '#1',\n"," '#1',\n"," '#win',\n"," '#DBOSS',\n"," '#asn',\n"," '#Kgf',\n"," '#2',\n"," '#ASN',\n"," '#rcbedarcbbeku',\n"," '#stunning',\n"," '#',\n"," '#ASN',\n"," '#No',\n"," '#diya....',\n"," '#ದಿಯಾ',\n"," '#Shaanvi.',\n"," '#vijayprakash',\n"," '#1',\n"," '#ASN!',\n"," '#',\n"," '#Slowpoison',\n"," '#ASN',\n"," '##',\n"," '##n',\n"," '#avanesrimannarayana',\n"," '#ASN',\n"," '#ASN',\n"," '#1',\n"," '#Dia',\n"," '#trending',\n"," '#ASN',\n"," '#DBoss',\n"," '#Vp',\n"," '#ASN',\n"," \"#'Hands\",\n"," '#BOSS',\n"," '#u',\n"," '#1',\n"," '#ಮಸ್ತಮಗಾ',\n"," '#PruthviAmber',\n"," '##jai',\n"," '#Shanvi_Srivatsava',\n"," '#Rakshit_Shetty',\n"," '#Rashmika_Mandanna',\n"," '#rashmikamandhana',\n"," '#ASN',\n"," '#1.46',\n"," '#ASN',\n"," '#KGFCHAPTER2',\n"," '#KGF2',\n"," '#DBOSS',\n"," '#AvanesrimannarayananAll',\n"," '#ಕ್ರಿಯೇಟಿವ್',\n"," '#ಕನ್ನಡ',\n"," '#ಧನ್ಯವಾದಗಳು',\n"," '#ಕರ್ನಾಟಕ',\n"," '#ಪ್ರಜ್ವಲ್',\n"," '#ASN',\n"," '#dboss',\n"," '#1']"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f-yI9rSBtZYG","executionInfo":{"status":"ok","timestamp":1610237936083,"user_tz":-330,"elapsed":6553,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"213f145f-8ea1-44d9-dde2-17c4f06bb3a7"},"source":["!pip install wordsegment"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Collecting wordsegment\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/6c/e6f4734d6f7d28305f52ec81377d7ce7d1856b97b814278e9960183235ad/wordsegment-1.3.1-py2.py3-none-any.whl (4.8MB)\n","     |████████████████████████████████| 4.8MB 8.3MB/s \n","\u001b[?25hInstalling collected packages: wordsegment\n","Successfully installed wordsegment-1.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbWsB03_qQCn","executionInfo":{"status":"ok","timestamp":1610238028855,"user_tz":-330,"elapsed":1487,"user":{"displayName":"Kushal Kedia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgUcyZnmbbRRgeqAp1TfWBxUa_rY5eK6djHslS6Jw=s64","userId":"08490086646661819003"}},"outputId":"7ece66ec-1acd-4582-8324-8b10387da362"},"source":["from wordsegment import segment, load\n","load()\n","ans = 'no_rakshaa_marana_mass'\n","ans = 'Pradesh_______________G'\n","segment(ans)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['pradesh', 'g']"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"igSNYLB6D1G8"},"source":["# Save and Load Functions\n","def save_metrics(save_path, epochs, model, optimizer, F1):\n","\n","    state_dict = {'model_state_dict': model.state_dict(),\n","                  'optimizer_state_dict': optimizer.state_dict(),\n","                  'epochs': epochs+1,\n","                  'F1': F1}\n","    \n","    torch.save(state_dict, save_path)\n","    print(f'Model saved to ==> {save_path}')\n","\n","\n","def load_metrics(load_path, model, optimizer):\n","    try: \n","        state_dict = torch.load(load_path, map_location=device)\n","        model.load_state_dict(state_dict['model_state_dict'])\n","        optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n","    except: \n","        state_dict = {}\n","\n","    print(f'Model loaded from <== {load_path}')\n","    \n","    return state_dict.get('epochs', 0), state_dict.get('F1', 0)\n","\n","def load_metrics_new(load_path, model):\n","    try: \n","        state_dict = torch.load(load_path, map_location=device)\n","        model.load_state_dict(state_dict['model_state_dict'])\n","        # optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n","    except: \n","        state_dict = {}\n","\n","    print(f'Model loaded from <== {load_path}')\n","    \n","    return state_dict.get('epochs', 0), state_dict.get('F1', 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJ1hfitc4CUl"},"source":["class Transform(torch.nn.Module):\n","    def __init__(self, D_in, num_labels):\n","        super(Transform, self).__init__()\n","        self.embeddings = AutoModel.from_pretrained(model_path)\n","        self.dropout = nn.Dropout(0.3)\n","        self.final = nn.Linear(D_in*2, num_labels, bias = True)\n","\n","    def forward(self, input_ids, mask):\n","        outputs = self.embeddings(input_ids, mask)\n","        out = outputs.last_hidden_state\n","        mean_pooling = torch.mean(out, 1)\n","        max_pooling, _ = torch.max(out, 1)\n","\n","        embed = torch.cat((mean_pooling, max_pooling), 1)\n","        y_pred = self.final(self.dropout(embed))\n","        return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NFqtqQcPvli0"},"source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"," \n","def get_predicted(preds):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    return pred_flat\n"," \n","def evaluate(test_dataloader, model):\n","    model.eval()\n","    y_preds, y_test = np.array([]), np.array([])\n","\n","    for batch in test_dataloader:\n","        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device).long()\n","        with torch.no_grad():        \n","            ypred = model(b_input_ids, b_input_mask)\n","        ypred = ypred.cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        y_preds = np.hstack((y_preds, get_predicted(ypred)))\n","        y_test = np.hstack((y_test, label_ids))\n","\n","    weighted_f1 = f1_score(y_test, y_preds, average='weighted')\n","    return weighted_f1, y_preds, y_test\n"," \n","def train(training_dataloader, validation_dataloader, model, filepath, weights = None, learning_rate = 2e-5, epochs = 4, print_every = 10):\n","    total_steps = len(training_dataloader) * epochs\n","    no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps = 1e-8)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                num_warmup_steps = 0, # Default value in run_glue.py\n","                                                num_training_steps = total_steps)\n","    \n","    current_epoch, best_weighted_f1 = load_metrics(filepath, model, optimizer)\n","    if weights == None:\n","        criterion = nn.CrossEntropyLoss()\n","    else:\n","        criterion = nn.CrossEntropyLoss(weight=weights)\n","    for epoch_i in tqdm(range(current_epoch, epochs)):\n","        model.train()\n","        for step, batch in enumerate(training_dataloader):\n","            b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device).long()\n","            \n","            outputs = model(b_input_ids, b_input_mask)\n","            loss = criterion(outputs, b_labels)\n"," \n","            if step%print_every == 0:\n","                print(loss.item())\n"," \n","            optimizer.zero_grad()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","            scheduler.step()\n"," \n","        print('### Validation Set Stats')\n","        weighted_f1, ypred, ytest = evaluate(validation_dataloader, model)\n","        print(\"  Weighted F1: {0:.2f}\".format(weighted_f1))\n","        if weighted_f1 > best_weighted_f1:\n","            best_weighted_f1 = weighted_f1\n","            save_metrics(filepath, epoch_i, model, optimizer, weighted_f1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YMgZPosD1sTc"},"source":["model = Transform(768, 5).to(device)\n","optimizer = AdamW(model.parameters(), lr=2e-5, eps = 1e-8)\n","no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias']\n","optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5, eps = 1e-8)\n","# load_metrics('olid_xlmr_base.pt', model, optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajtMXUcMQ3Te","executionInfo":{"status":"ok","timestamp":1610199212146,"user_tz":-330,"elapsed":161484,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"}},"outputId":"6d31de35-d1e3-4b8e-f8cc-986ef456a2a0"},"source":["# save_metrics('olid_xlmr_base_embed.pt', -1, model.embeddings, optimizer, -1)\n","model = Transform(768, 6).to(device)\n","load_metrics_new('olid_xlmr_base_embed_new.pt', model.embeddings)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model loaded from <== olid_xlmr_base_embed_new.pt\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(3, 0.8405510904977567)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0ufvYfIYwuS","executionInfo":{"status":"ok","timestamp":1610206605315,"user_tz":-330,"elapsed":7550827,"user":{"displayName":"Kushal Kedia","photoUrl":"","userId":"17515642502776479988"}},"outputId":"e547b70a-a00b-4492-a6a8-3a636bd3492e"},"source":["train(data.train_dataloader, data.val_dataloader, model, 'olid_xlmr_tamil_new.pt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model loaded from <== olid_xlmr_tamil_new.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/4 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["1.3827037811279297\n","0.707119882106781\n","0.5697749853134155\n","0.8126499056816101\n","0.7258977293968201\n","0.3760716915130615\n","0.6903999447822571\n","0.5676354765892029\n","0.7841488122940063\n","\n","0.9662981629371643\n","0.6774706244468689\n","0.8256979584693909\n","0.6239492893218994\n","0.4127058684825897\n","0.37586748600006104\n","0.7699794173240662\n","0.7174965143203735\n","1.0236085653305054\n","0.9283753037452698\n","0.6038984060287476\n","0.47299477458000183\n","0.726555585861206\n","1.0698517560958862\n","0.5911938548088074\n","0.9037986993789673\n","0.9411525726318359\n","0.7520509958267212\n","0.83879154920578\n","0.3930736482143402\n","0.5956424474716187\n","0.5345407128334045\n","0.6719488501548767\n","0.5271205306053162\n","0.6932833194732666\n","1.1580049991607666\n","0.4742433428764343\n","0.9651106595993042\n","0.7170631289482117\n","0.5074365735054016\n","0.8433086276054382\n","0.9022130370140076\n","0.8905602097511292\n","0.8149163722991943\n","0.5376572608947754\n","0.7340426445007324\n","0.5734100341796875\n","0.7564501762390137\n","0.416908860206604\n","0.5136358141899109\n","0.5415738224983215\n","0.7176908254623413\n","0.8215780258178711\n","0.49436673521995544\n","0.610353946685791\n","0.7765643000602722\n","0.5033466219902039\n","0.5776028633117676\n","0.8285574913024902\n","0.7916907072067261\n","0.9000896215438843\n","0.5205745100975037\n","0.6527491211891174\n","0.799512505531311\n","0.4441833794116974\n","0.770046055316925\n","0.843447208404541\n","1.0531777143478394\n","0.4467151463031769\n","0.7547980546951294\n","0.3770338296890259\n","0.7449547052383423\n","0.4259111285209656\n","0.5472845435142517\n","0.5963490009307861\n","0.5041790008544922\n","0.8631342053413391\n","0.45478808879852295\n","0.3529943823814392\n","1.160949468612671\n","0.5618885159492493\n","0.5269777774810791\n","0.5764058232307434\n","0.2959073781967163\n","0.4895796775817871\n","0.7908204793930054\n","0.7492760419845581\n","0.8310664892196655\n","0.7878623604774475\n","0.6491361856460571\n","0.6850603818893433\n","0.8036933541297913\n","0.4781033992767334\n","0.42715582251548767\n","0.5471594929695129\n","0.7942295074462891\n","0.39454394578933716\n","0.9649959802627563\n","0.6948586702346802\n","0.9440973997116089\n","0.8235227465629578\n","0.5211295485496521\n","0.7859565019607544\n","0.4974129796028137\n","0.6125938892364502\n","0.6658989787101746\n","0.6543261408805847\n","0.574347972869873\n","0.6579770445823669\n","0.5907095074653625\n","### Validation Set Stats\n","  Weighted F1: 0.75\n","Model saved to ==> olid_xlmr_tamil_new.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 25%|██▌       | 1/4 [30:44<1:32:14, 1844.76s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.7933605909347534\n","0.5151197910308838\n","0.5166828632354736\n","0.46889933943748474\n","0.9520547389984131\n","0.8959338068962097\n","0.42427942156791687\n","0.47711795568466187\n","0.46560126543045044\n","0.5400868654251099\n","0.6178332567214966\n","0.5327184200286865\n","0.6397090554237366\n","0.3624483048915863\n","0.4193245768547058\n","0.6319773197174072\n","0.3282817602157593\n","0.8783979415893555\n","0.4085277020931244\n","0.6466694474220276\n","0.5888128280639648\n","0.4689101576805115\n","0.40321406722068787\n","0.35843271017074585\n","0.5046445727348328\n","0.5234825015068054\n","0.39294034242630005\n","0.6316843032836914\n","0.6147304177284241\n","0.7901074290275574\n","0.7911117076873779\n","0.6955722570419312\n","0.7148879766464233\n","0.9732711315155029\n","0.6275277137756348\n","0.6134104132652283\n","0.6413905620574951\n","0.40025800466537476\n","0.7028116583824158\n","0.8608729839324951\n","0.5303041338920593\n","0.5391413569450378\n","0.5851832628250122\n","0.7702240943908691\n","0.9642824530601501\n","0.6209015250205994\n","0.4587070345878601\n","0.5528832674026489\n","0.7994793057441711\n","0.36921024322509766\n","0.4919770359992981\n","0.5487979650497437\n","0.8257671594619751\n","0.68442702293396\n","0.7318096160888672\n","0.5514838695526123\n","0.47248899936676025\n","0.6482757925987244\n","0.7335691452026367\n","0.6122208833694458\n","0.46677452325820923\n","0.4161425530910492\n","0.7459875345230103\n","0.7488210201263428\n","0.4709659814834595\n","0.2456398606300354\n","0.6359239220619202\n","0.44255754351615906\n","0.2613682746887207\n","0.842128574848175\n","0.21942006051540375\n","0.24967263638973236\n","0.731328010559082\n","0.7229593396186829\n","0.48109227418899536\n","0.8341871500015259\n","0.36849406361579895\n","0.6994227766990662\n","0.6425111889839172\n","0.44396212697029114\n","0.5006964802742004\n","0.43814852833747864\n","0.5046785473823547\n","0.34118619561195374\n","0.7040259838104248\n","0.5584329962730408\n","0.7121021151542664\n","0.7191684246063232\n","0.9161659479141235\n","0.33034366369247437\n","0.7726554870605469\n","0.5879490971565247\n","0.43788135051727295\n","0.5900978446006775\n","0.8180025219917297\n","0.621497631072998\n","0.6801793575286865\n","0.39681434631347656\n","0.6716625094413757\n","0.4637978672981262\n","0.41707295179367065\n","0.3976260721683502\n","0.46192607283592224\n","0.5001173615455627\n","0.3296571969985962\n","0.4337477385997772\n","0.594155490398407\n","0.6913861036300659\n","0.548334002494812\n","0.8342831134796143\n","### Validation Set Stats\n","  Weighted F1: 0.75\n","Model saved to ==> olid_xlmr_tamil_new.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 2/4 [1:01:33<1:01:32, 1846.04s/it]"],"name":"stderr"},{"output_type":"stream","text":["0.4885443449020386\n","0.8822228312492371\n","0.7324984669685364\n","0.3435123860836029\n","\n","0.5732443928718567\n","0.5000120401382446\n","0.42473259568214417\n","0.5671505928039551\n","0.44952505826950073\n","0.43027371168136597\n","0.46255096793174744\n","0.3511328101158142\n","0.549448549747467\n","0.8108782768249512\n","0.6124988198280334\n","0.35077449679374695\n","0.5348209142684937\n","0.688344419002533\n","0.29810523986816406\n","0.6902356743812561\n","0.5786144733428955\n","0.5910938382148743\n","0.5006276965141296\n","0.5537449717521667\n","0.2786235511302948\n","0.4176810085773468\n","0.3546854853630066\n","0.11333626508712769\n","0.24400822818279266\n","0.6662166714668274\n","0.5485678911209106\n","0.5094572305679321\n","0.3810337483882904\n","0.3550266623497009\n","0.716845691204071\n","0.3990563452243805\n","0.36124494671821594\n","0.6315447092056274\n","0.422586590051651\n","0.3099980652332306\n","0.39722853899002075\n","0.7008979916572571\n","0.607639729976654\n","0.5055176615715027\n","0.4090156853199005\n","0.7828459739685059\n","0.5812380909919739\n","0.3243483603000641\n","0.8141909241676331\n","0.39077743887901306\n","0.4104311168193817\n","0.2794378995895386\n","0.6387025117874146\n","0.6312811374664307\n","0.6672729849815369\n","0.6064575910568237\n","0.5943856835365295\n","0.2765811085700989\n","0.4174065589904785\n","0.3939981460571289\n","0.7935156226158142\n","0.3441151976585388\n","0.13698485493659973\n","0.433391809463501\n","0.6197795867919922\n","0.847099244594574\n","0.5828098654747009\n","0.6847286820411682\n","0.5281454920768738\n","0.736362636089325\n","0.5029080510139465\n","0.270440936088562\n","0.3475247323513031\n","0.5692662000656128\n","0.414407342672348\n","0.6340921521186829\n","0.45724281668663025\n","0.6533352732658386\n","0.5656179189682007\n","0.3300118148326874\n","0.6004770398139954\n","0.3855440318584442\n","0.3644741475582123\n","0.45514535903930664\n","0.2872472107410431\n","0.4539927840232849\n","0.33301159739494324\n","0.806590735912323\n","0.6273552775382996\n","0.5610327124595642\n","0.4732658267021179\n","0.46855664253234863\n","0.2670721411705017\n","0.5385857820510864\n","0.5458289384841919\n","0.6218323707580566\n","0.5155683159828186\n","0.6726133227348328\n","0.5771042108535767\n","0.6910924315452576\n","0.26034051179885864\n","0.6635041832923889\n","0.5591630339622498\n","0.3126426935195923\n","0.7475959658622742\n","0.8625022768974304\n","0.4695149064064026\n","0.5342546701431274\n","0.38642776012420654\n","### Validation Set Stats\n","  Weighted F1: 0.77\n","Model saved to ==> olid_xlmr_tamil_new.pt\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|███████▌  | 3/4 [1:32:24<30:47, 1847.48s/it]  "],"name":"stderr"},{"output_type":"stream","text":["0.6547251343727112\n","0.7879370450973511\n","0.6123150587081909\n","0.445584237575531\n","0.4572160542011261\n","0.6254869103431702\n","0.5910829901695251\n","0.5909932255744934\n","0.5006228685379028\n","0.37875616550445557\n","0.6272394061088562\n","0.3367610573768616\n","0.44425633549690247\n","0.3940967917442322\n","0.5128639340400696\n","0.3253736197948456\n","0.5020584464073181\n","0.38453999161720276\n","0.4458157420158386\n","0.3809550404548645\n","0.17242690920829773\n","0.441678911447525\n","0.3079788088798523\n","0.6551818251609802\n","0.4938412308692932\n","0.3514661490917206\n","0.1946377456188202\n","0.3489604890346527\n","0.3526236116886139\n","0.4102954566478729\n","0.15892374515533447\n","0.2711177170276642\n","0.478920578956604\n","0.1888723373413086\n","0.3949044644832611\n","0.2829122543334961\n","0.740734338760376\n","0.646075963973999\n","0.6948750615119934\n","0.19991141557693481\n","0.43339142203330994\n","0.5855204463005066\n","0.4017508029937744\n","0.33921656012535095\n","0.5164597630500793\n","0.3450016677379608\n","0.2790840268135071\n","0.1697201132774353\n","0.7202146053314209\n","0.7646333575248718\n","0.2637281119823456\n","0.5711539387702942\n","0.25097963213920593\n","0.3845418393611908\n","0.4012291133403778\n","0.3970479369163513\n","0.2902314066886902\n","0.6603142619132996\n","0.28536877036094666\n","0.3633940815925598\n","0.21646563708782196\n","0.345771849155426\n","0.3583201766014099\n","0.5846570730209351\n","0.29936450719833374\n","0.4305277466773987\n","0.5944406390190125\n","0.31400230526924133\n","0.5196332335472107\n","0.6068745851516724\n","0.19398175179958344\n","0.6522230505943298\n","0.4559745192527771\n","0.5495971441268921\n","0.3786951005458832\n","0.4671986401081085\n","0.6088806390762329\n","0.19037069380283356\n","0.29660797119140625\n","0.5117833018302917\n","0.29585716128349304\n","0.30041608214378357\n","0.318657249212265\n","0.3513844907283783\n","0.29430416226387024\n","0.26789507269859314\n","0.48046985268592834\n","0.5405340790748596\n","0.18534888327121735\n","0.437294065952301\n","0.2391251027584076\n","0.3782714009284973\n","0.4596603512763977\n","0.42931297421455383\n","0.33016952872276306\n","0.2554091811180115\n","0.19001264870166779\n","0.5778640508651733\n","0.2319396585226059\n","0.37354549765586853\n","0.7613181471824646\n","0.23130837082862854\n","0.4813205599784851\n","0.6928569078445435\n","0.48986974358558655\n","0.522986650466919\n","0.46658772230148315\n","0.27672648429870605\n","0.5069829225540161\n","0.7016627788543701\n","### Validation Set Stats\n","  Weighted F1: 0.77\n","Model saved to ==> olid_xlmr_tamil_new.pt\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 4/4 [2:03:13<00:00, 1848.33s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"lNAl6mrYTQOr"},"source":["load_metrics_new('olid_xlmr_tamil_new.pt', model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"quTk_hanRRav"},"source":["_, ypred, ytest = evaluate(data.val_dataloader, model)\n","from sklearn.metrics import confusion_matrix\n","array = confusion_matrix(ytest, ypred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZ588U8OTEsh"},"source":["import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","df_cm = pd.DataFrame(array, range(6), range(6))\n","# plt.figure(figsize=(10,7))\n","sn.set(font_scale=1.4) # for label size\n","sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6VHS7N5x6YP"},"source":["train(data.train_dataloader, data.val_dataloader, model, 'tamil_mal.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gxwu-UTlzJVo"},"source":[""],"execution_count":null,"outputs":[]}]}